# 1. Linear regression 推导过程

# 2. mapreduce工作原理

MapReduce模型主要包含Mapper类和Reducer类。Mapper类主要负责对数据的分析处理，最终转化为key-value数据对；Reducer类主要获取key-value数据对，然后处理统计，得到结果。MapReduce实现了存储的均衡，但没有实现计算的均衡。

- MapReduce框架组成
MapReduce主要包括JobClient、JobTracker、TaskTracker、HDFS四个独立的部分。

> - JobClient

配置参数Configuration，并打包成jar文件存储在HDFS上，将文件路径提交给JobTracker的master服务，然后由master创建每个task将它们分发到各个TaskTracker服务中去执行。

> - JobTracker

这是一个master服务，程序启动后，JobTracker负责资源监控和作业调度。JobTracker监控所有的TaskTracker和job的健康状况，一旦发生失败，即将之转移到其它节点上，同时JobTracker会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器，而调度器会在资源出现空闲时，选择合适的任务使用这些资源。在Hadoop中，任务调度器是一个可插拔的模块，用户可以根据自己的需要设计相应的调度器。

> - TaskTracker


运行多个节点上的slaver服务。TaskTracker主动与JobTracker通信接受作业，并负责直接执行每个任务。TaskTracker会周期性地通过Hearbeat将本节点上资源的使用情况和任务的运行进度汇报给JobTracker，同时接受JobTracker发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）。

TaskTracker使用“slot”等量划分本节点上的资源。“slot”代表计算资源（CPU、内存等）。一个Task获取到一个slot后才有机会运行，而Hadoop调度器的作用就是将各个TaskTracker上的空闲slot分配给Task使用。

> - HDFS


- MapReduce程序运行过程

1. 作业运行过程

> - 首先向JobTracker请求一个新的作业ID；
> - 然后检查输出说明（如输出目录已存在）、输出划分（如输入路径不存在）；
> - JobTracker配置好所有需要的资源，然后把作业放入到一个内部的队列中，并对其进行初始化，初始化包括创建一个代表该正在运行的作业对象，一边跟踪任务的状态和进程；
> - 作业调度器获取分片信息，每个分片创建一个map任务

2. MapReduce逻辑角度分析作业运行顺序：输入分片(input split)、map阶段、combiner阶段、shuffle阶段、reduce阶段
> - input split: 在map计算之前，程序会根据输入文件计算split，每个input split针对一个map任务。input split存储的并非是数据本身，而是一个分片长度和一个记录数据的位置的数组。
> - map阶段： 执行map函数
> - combiner阶段：这是一个可选择的函数，实质上是一种reduce操作。combiner是map的后续操作，主要是在map计算出中间文件前做一个简单的合并重复key值的操作。
> - shuffle阶段：指从map输出开始，包括系统执行排序即传送mao输出到reduce作为输入的过程。另外针对map输出的key进行排序，又叫sort阶段。map端shuffle，简单来说就是利用combiner对数据进行预排序，利用内存缓冲区来完成。reduce端的shuffle包括复制数据和归并数据，最终产生一个reduce输入文件。shuffle过程有许多可调优的参数来提高MapReduce的性能，其总原则就是给shuffle过程尽量多的内存空间。
> - reduce阶段：即执行reduce函数并存到hdfs文件系统中。

# 3. MapReduce WordCount例子


# 4. 二分查找
# 5. 模型选择
